{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3jmRXdT0EjFSj2KcAh0RB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaustubhPendharkar/Colab-samples/blob/Trial1/00_Keras_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svqAd5hBHwaa",
        "outputId": "acb12661-e02a-4f51-a4a3-5886d5dc4a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN nsubj\n",
            "is AUX aux\n",
            "looking VERB ROOT\n",
            "at ADP prep\n",
            "buying VERB pcomp\n",
            "U.S. PROPN compound\n",
            "startup NOUN dobj\n",
            "for ADP prep\n",
            "$ SYM quantmod\n",
            "6 NUM compound\n",
            "million NUM pobj\n"
          ]
        }
      ],
      "source": [
        "# Import spaCy and load the language library\n",
        "import spacy\n",
        "\n",
        "#nlp = spacy.load('en_core_web_sm')\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "# Create a Doc object\n",
        "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
        "\n",
        "# Print each token separately\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xLF4hra4H-5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "ZwKdOx0mILOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "brtcncr = load_breast_cancer()"
      ],
      "metadata": {
        "id": "MW1HvVNwINxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type (iris)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu4EGTUYIRLK",
        "outputId": "b62ddbc8-26ec-4811-8c06-68a20fdcd90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (iris.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMQpFI0oITVJ",
        "outputId": "ca00aa62-1f92-435a-aab0-a37360b1defc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data"
      ],
      "metadata": {
        "id": "ndd8lnAQIVPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5GdAeB6IYlI",
        "outputId": "8b55d909-9666-4e5e-aecc-44b88ff42a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = iris.target"
      ],
      "metadata": {
        "id": "1mfbHhAYIZ5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz_hd7JiIcZQ",
        "outputId": "1138f3be-9384-4de2-d14a-8bef1c2a54c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "TXmU5fYaIdj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical (y)"
      ],
      "metadata": {
        "id": "bCJpynubIgFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fZvm07DMGH0",
        "outputId": "871b09dd-d73c-46af-a16b-6b00bacdabc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP3MpjHRMH0M",
        "outputId": "46838f4c-cfde-4944-c418-e581c58d1bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iitkz1COMKKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=.33, random_state=42)"
      ],
      "metadata": {
        "id": "EHBYNDaQMXU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYgB8ri8Ml6e",
        "outputId": "92415e0f-fcae-49af-ecce-070719139fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7, 2.9, 4.2, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [7.1, 3. , 5.9, 2.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "f28zQF7uMoF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_object = MinMaxScaler()"
      ],
      "metadata": {
        "id": "bhTZXwncMyUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_object.fit (X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "SKKmTFS0M1_P",
        "outputId": "d94c6b5c-8750-41d5-e10a-ecfa259c956f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X_train = scaler_object.transform (X_train)"
      ],
      "metadata": {
        "id": "swRUd9-9M5yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X_test = scaler_object.transform (X_test)"
      ],
      "metadata": {
        "id": "z1KOcToqNGP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6S7mtw6NMrI",
        "outputId": "81fa2cad-4b3f-46b5-cf8e-0ae323a3e3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.7"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X_train.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_olkggK7NSSi",
        "outputId": "f7552811-be6f-44bc-8e81-8c5680ad850b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "N8COHmR6NY9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jdmqcR5aOmbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1Kx1xmeOnaF",
        "outputId": "8a36b339-7ddc-4a0d-819c-93b8f7f0e1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139 (556.00 Byte)\n",
            "Trainable params: 139 (556.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Play around with number of epochs as well!\n",
        "model.fit(scaled_X_train,y_train,epochs=150, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZUGZ3bNO3EW",
        "outputId": "8fa749e4-02db-47eb-a794-5dba99caa8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "4/4 - 0s - loss: 0.5944 - accuracy: 0.9000 - 16ms/epoch - 4ms/step\n",
            "Epoch 2/150\n",
            "4/4 - 0s - loss: 0.5927 - accuracy: 0.9100 - 15ms/epoch - 4ms/step\n",
            "Epoch 3/150\n",
            "4/4 - 0s - loss: 0.5910 - accuracy: 0.9100 - 14ms/epoch - 3ms/step\n",
            "Epoch 4/150\n",
            "4/4 - 0s - loss: 0.5892 - accuracy: 0.9000 - 13ms/epoch - 3ms/step\n",
            "Epoch 5/150\n",
            "4/4 - 0s - loss: 0.5875 - accuracy: 0.9100 - 14ms/epoch - 4ms/step\n",
            "Epoch 6/150\n",
            "4/4 - 0s - loss: 0.5858 - accuracy: 0.9100 - 15ms/epoch - 4ms/step\n",
            "Epoch 7/150\n",
            "4/4 - 0s - loss: 0.5840 - accuracy: 0.9100 - 15ms/epoch - 4ms/step\n",
            "Epoch 8/150\n",
            "4/4 - 0s - loss: 0.5824 - accuracy: 0.9100 - 13ms/epoch - 3ms/step\n",
            "Epoch 9/150\n",
            "4/4 - 0s - loss: 0.5807 - accuracy: 0.9100 - 14ms/epoch - 4ms/step\n",
            "Epoch 10/150\n",
            "4/4 - 0s - loss: 0.5793 - accuracy: 0.9100 - 16ms/epoch - 4ms/step\n",
            "Epoch 11/150\n",
            "4/4 - 0s - loss: 0.5776 - accuracy: 0.9200 - 14ms/epoch - 4ms/step\n",
            "Epoch 12/150\n",
            "4/4 - 0s - loss: 0.5761 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n",
            "Epoch 13/150\n",
            "4/4 - 0s - loss: 0.5741 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n",
            "Epoch 14/150\n",
            "4/4 - 0s - loss: 0.5731 - accuracy: 0.9100 - 14ms/epoch - 3ms/step\n",
            "Epoch 15/150\n",
            "4/4 - 0s - loss: 0.5720 - accuracy: 0.9200 - 14ms/epoch - 4ms/step\n",
            "Epoch 16/150\n",
            "4/4 - 0s - loss: 0.5701 - accuracy: 0.9100 - 16ms/epoch - 4ms/step\n",
            "Epoch 17/150\n",
            "4/4 - 0s - loss: 0.5679 - accuracy: 0.9200 - 17ms/epoch - 4ms/step\n",
            "Epoch 18/150\n",
            "4/4 - 0s - loss: 0.5669 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n",
            "Epoch 19/150\n",
            "4/4 - 0s - loss: 0.5655 - accuracy: 0.9200 - 14ms/epoch - 4ms/step\n",
            "Epoch 20/150\n",
            "4/4 - 0s - loss: 0.5638 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n",
            "Epoch 21/150\n",
            "4/4 - 0s - loss: 0.5619 - accuracy: 0.9200 - 14ms/epoch - 4ms/step\n",
            "Epoch 22/150\n",
            "4/4 - 0s - loss: 0.5603 - accuracy: 0.9200 - 21ms/epoch - 5ms/step\n",
            "Epoch 23/150\n",
            "4/4 - 0s - loss: 0.5587 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n",
            "Epoch 24/150\n",
            "4/4 - 0s - loss: 0.5573 - accuracy: 0.9200 - 13ms/epoch - 3ms/step\n",
            "Epoch 25/150\n",
            "4/4 - 0s - loss: 0.5558 - accuracy: 0.9300 - 16ms/epoch - 4ms/step\n",
            "Epoch 26/150\n",
            "4/4 - 0s - loss: 0.5544 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n",
            "Epoch 27/150\n",
            "4/4 - 0s - loss: 0.5526 - accuracy: 0.9300 - 19ms/epoch - 5ms/step\n",
            "Epoch 28/150\n",
            "4/4 - 0s - loss: 0.5511 - accuracy: 0.9300 - 21ms/epoch - 5ms/step\n",
            "Epoch 29/150\n",
            "4/4 - 0s - loss: 0.5493 - accuracy: 0.9300 - 15ms/epoch - 4ms/step\n",
            "Epoch 30/150\n",
            "4/4 - 0s - loss: 0.5476 - accuracy: 0.9300 - 15ms/epoch - 4ms/step\n",
            "Epoch 31/150\n",
            "4/4 - 0s - loss: 0.5456 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n",
            "Epoch 32/150\n",
            "4/4 - 0s - loss: 0.5439 - accuracy: 0.9300 - 14ms/epoch - 3ms/step\n",
            "Epoch 33/150\n",
            "4/4 - 0s - loss: 0.5423 - accuracy: 0.9300 - 14ms/epoch - 4ms/step\n",
            "Epoch 34/150\n",
            "4/4 - 0s - loss: 0.5406 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n",
            "Epoch 35/150\n",
            "4/4 - 0s - loss: 0.5387 - accuracy: 0.9300 - 12ms/epoch - 3ms/step\n",
            "Epoch 36/150\n",
            "4/4 - 0s - loss: 0.5371 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n",
            "Epoch 37/150\n",
            "4/4 - 0s - loss: 0.5363 - accuracy: 0.9400 - 13ms/epoch - 3ms/step\n",
            "Epoch 38/150\n",
            "4/4 - 0s - loss: 0.5345 - accuracy: 0.9400 - 16ms/epoch - 4ms/step\n",
            "Epoch 39/150\n",
            "4/4 - 0s - loss: 0.5331 - accuracy: 0.9500 - 15ms/epoch - 4ms/step\n",
            "Epoch 40/150\n",
            "4/4 - 0s - loss: 0.5309 - accuracy: 0.9400 - 17ms/epoch - 4ms/step\n",
            "Epoch 41/150\n",
            "4/4 - 0s - loss: 0.5292 - accuracy: 0.9300 - 14ms/epoch - 4ms/step\n",
            "Epoch 42/150\n",
            "4/4 - 0s - loss: 0.5278 - accuracy: 0.9300 - 17ms/epoch - 4ms/step\n",
            "Epoch 43/150\n",
            "4/4 - 0s - loss: 0.5261 - accuracy: 0.9300 - 15ms/epoch - 4ms/step\n",
            "Epoch 44/150\n",
            "4/4 - 0s - loss: 0.5244 - accuracy: 0.9300 - 15ms/epoch - 4ms/step\n",
            "Epoch 45/150\n",
            "4/4 - 0s - loss: 0.5230 - accuracy: 0.9400 - 19ms/epoch - 5ms/step\n",
            "Epoch 46/150\n",
            "4/4 - 0s - loss: 0.5214 - accuracy: 0.9300 - 16ms/epoch - 4ms/step\n",
            "Epoch 47/150\n",
            "4/4 - 0s - loss: 0.5197 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n",
            "Epoch 48/150\n",
            "4/4 - 0s - loss: 0.5182 - accuracy: 0.9400 - 20ms/epoch - 5ms/step\n",
            "Epoch 49/150\n",
            "4/4 - 0s - loss: 0.5166 - accuracy: 0.9400 - 15ms/epoch - 4ms/step\n",
            "Epoch 50/150\n",
            "4/4 - 0s - loss: 0.5150 - accuracy: 0.9500 - 16ms/epoch - 4ms/step\n",
            "Epoch 51/150\n",
            "4/4 - 0s - loss: 0.5135 - accuracy: 0.9500 - 14ms/epoch - 4ms/step\n",
            "Epoch 52/150\n",
            "4/4 - 0s - loss: 0.5119 - accuracy: 0.9500 - 14ms/epoch - 3ms/step\n",
            "Epoch 53/150\n",
            "4/4 - 0s - loss: 0.5105 - accuracy: 0.9500 - 13ms/epoch - 3ms/step\n",
            "Epoch 54/150\n",
            "4/4 - 0s - loss: 0.5094 - accuracy: 0.9500 - 14ms/epoch - 4ms/step\n",
            "Epoch 55/150\n",
            "4/4 - 0s - loss: 0.5074 - accuracy: 0.9500 - 13ms/epoch - 3ms/step\n",
            "Epoch 56/150\n",
            "4/4 - 0s - loss: 0.5054 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 57/150\n",
            "4/4 - 0s - loss: 0.5035 - accuracy: 0.9500 - 13ms/epoch - 3ms/step\n",
            "Epoch 58/150\n",
            "4/4 - 0s - loss: 0.5029 - accuracy: 0.9300 - 16ms/epoch - 4ms/step\n",
            "Epoch 59/150\n",
            "4/4 - 0s - loss: 0.5014 - accuracy: 0.9300 - 27ms/epoch - 7ms/step\n",
            "Epoch 60/150\n",
            "4/4 - 0s - loss: 0.4994 - accuracy: 0.9300 - 17ms/epoch - 4ms/step\n",
            "Epoch 61/150\n",
            "4/4 - 0s - loss: 0.4975 - accuracy: 0.9500 - 15ms/epoch - 4ms/step\n",
            "Epoch 62/150\n",
            "4/4 - 0s - loss: 0.4979 - accuracy: 0.9500 - 18ms/epoch - 4ms/step\n",
            "Epoch 63/150\n",
            "4/4 - 0s - loss: 0.4950 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 64/150\n",
            "4/4 - 0s - loss: 0.4926 - accuracy: 0.9500 - 18ms/epoch - 4ms/step\n",
            "Epoch 65/150\n",
            "4/4 - 0s - loss: 0.4913 - accuracy: 0.9400 - 18ms/epoch - 5ms/step\n",
            "Epoch 66/150\n",
            "4/4 - 0s - loss: 0.4899 - accuracy: 0.9400 - 16ms/epoch - 4ms/step\n",
            "Epoch 67/150\n",
            "4/4 - 0s - loss: 0.4878 - accuracy: 0.9400 - 19ms/epoch - 5ms/step\n",
            "Epoch 68/150\n",
            "4/4 - 0s - loss: 0.4861 - accuracy: 0.9500 - 25ms/epoch - 6ms/step\n",
            "Epoch 69/150\n",
            "4/4 - 0s - loss: 0.4849 - accuracy: 0.9500 - 22ms/epoch - 6ms/step\n",
            "Epoch 70/150\n",
            "4/4 - 0s - loss: 0.4837 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 71/150\n",
            "4/4 - 0s - loss: 0.4828 - accuracy: 0.9400 - 18ms/epoch - 5ms/step\n",
            "Epoch 72/150\n",
            "4/4 - 0s - loss: 0.4815 - accuracy: 0.9400 - 18ms/epoch - 4ms/step\n",
            "Epoch 73/150\n",
            "4/4 - 0s - loss: 0.4795 - accuracy: 0.9400 - 16ms/epoch - 4ms/step\n",
            "Epoch 74/150\n",
            "4/4 - 0s - loss: 0.4778 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 75/150\n",
            "4/4 - 0s - loss: 0.4757 - accuracy: 0.9500 - 23ms/epoch - 6ms/step\n",
            "Epoch 76/150\n",
            "4/4 - 0s - loss: 0.4738 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 77/150\n",
            "4/4 - 0s - loss: 0.4724 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 78/150\n",
            "4/4 - 0s - loss: 0.4713 - accuracy: 0.9400 - 27ms/epoch - 7ms/step\n",
            "Epoch 79/150\n",
            "4/4 - 0s - loss: 0.4692 - accuracy: 0.9500 - 37ms/epoch - 9ms/step\n",
            "Epoch 80/150\n",
            "4/4 - 0s - loss: 0.4674 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 81/150\n",
            "4/4 - 0s - loss: 0.4659 - accuracy: 0.9500 - 26ms/epoch - 7ms/step\n",
            "Epoch 82/150\n",
            "4/4 - 0s - loss: 0.4645 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 83/150\n",
            "4/4 - 0s - loss: 0.4630 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 84/150\n",
            "4/4 - 0s - loss: 0.4618 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 85/150\n",
            "4/4 - 0s - loss: 0.4603 - accuracy: 0.9500 - 22ms/epoch - 6ms/step\n",
            "Epoch 86/150\n",
            "4/4 - 0s - loss: 0.4586 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 87/150\n",
            "4/4 - 0s - loss: 0.4569 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 88/150\n",
            "4/4 - 0s - loss: 0.4550 - accuracy: 0.9500 - 27ms/epoch - 7ms/step\n",
            "Epoch 89/150\n",
            "4/4 - 0s - loss: 0.4535 - accuracy: 0.9500 - 24ms/epoch - 6ms/step\n",
            "Epoch 90/150\n",
            "4/4 - 0s - loss: 0.4518 - accuracy: 0.9500 - 25ms/epoch - 6ms/step\n",
            "Epoch 91/150\n",
            "4/4 - 0s - loss: 0.4506 - accuracy: 0.9500 - 28ms/epoch - 7ms/step\n",
            "Epoch 92/150\n",
            "4/4 - 0s - loss: 0.4488 - accuracy: 0.9500 - 26ms/epoch - 6ms/step\n",
            "Epoch 93/150\n",
            "4/4 - 0s - loss: 0.4472 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 94/150\n",
            "4/4 - 0s - loss: 0.4458 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 95/150\n",
            "4/4 - 0s - loss: 0.4441 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 96/150\n",
            "4/4 - 0s - loss: 0.4428 - accuracy: 0.9500 - 24ms/epoch - 6ms/step\n",
            "Epoch 97/150\n",
            "4/4 - 0s - loss: 0.4405 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 98/150\n",
            "4/4 - 0s - loss: 0.4393 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 99/150\n",
            "4/4 - 0s - loss: 0.4387 - accuracy: 0.9500 - 23ms/epoch - 6ms/step\n",
            "Epoch 100/150\n",
            "4/4 - 0s - loss: 0.4379 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 101/150\n",
            "4/4 - 0s - loss: 0.4363 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 102/150\n",
            "4/4 - 0s - loss: 0.4336 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 103/150\n",
            "4/4 - 0s - loss: 0.4320 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 104/150\n",
            "4/4 - 0s - loss: 0.4304 - accuracy: 0.9500 - 22ms/epoch - 6ms/step\n",
            "Epoch 105/150\n",
            "4/4 - 0s - loss: 0.4292 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 106/150\n",
            "4/4 - 0s - loss: 0.4275 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 107/150\n",
            "4/4 - 0s - loss: 0.4258 - accuracy: 0.9500 - 16ms/epoch - 4ms/step\n",
            "Epoch 108/150\n",
            "4/4 - 0s - loss: 0.4245 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 109/150\n",
            "4/4 - 0s - loss: 0.4227 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 110/150\n",
            "4/4 - 0s - loss: 0.4218 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n",
            "Epoch 111/150\n",
            "4/4 - 0s - loss: 0.4229 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 112/150\n",
            "4/4 - 0s - loss: 0.4206 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 113/150\n",
            "4/4 - 0s - loss: 0.4173 - accuracy: 0.9500 - 23ms/epoch - 6ms/step\n",
            "Epoch 114/150\n",
            "4/4 - 0s - loss: 0.4152 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 115/150\n",
            "4/4 - 0s - loss: 0.4137 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 116/150\n",
            "4/4 - 0s - loss: 0.4123 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n",
            "Epoch 117/150\n",
            "4/4 - 0s - loss: 0.4108 - accuracy: 0.9500 - 23ms/epoch - 6ms/step\n",
            "Epoch 118/150\n",
            "4/4 - 0s - loss: 0.4091 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n",
            "Epoch 119/150\n",
            "4/4 - 0s - loss: 0.4080 - accuracy: 0.9500 - 23ms/epoch - 6ms/step\n",
            "Epoch 120/150\n",
            "4/4 - 0s - loss: 0.4073 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 121/150\n",
            "4/4 - 0s - loss: 0.4060 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 122/150\n",
            "4/4 - 0s - loss: 0.4032 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 123/150\n",
            "4/4 - 0s - loss: 0.4028 - accuracy: 0.9500 - 18ms/epoch - 4ms/step\n",
            "Epoch 124/150\n",
            "4/4 - 0s - loss: 0.4044 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n",
            "Epoch 125/150\n",
            "4/4 - 0s - loss: 0.4032 - accuracy: 0.9400 - 25ms/epoch - 6ms/step\n",
            "Epoch 126/150\n",
            "4/4 - 0s - loss: 0.4002 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 127/150\n",
            "4/4 - 0s - loss: 0.3968 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n",
            "Epoch 128/150\n",
            "4/4 - 0s - loss: 0.3954 - accuracy: 0.9500 - 24ms/epoch - 6ms/step\n",
            "Epoch 129/150\n",
            "4/4 - 0s - loss: 0.3941 - accuracy: 0.9500 - 22ms/epoch - 6ms/step\n",
            "Epoch 130/150\n",
            "4/4 - 0s - loss: 0.3927 - accuracy: 0.9500 - 24ms/epoch - 6ms/step\n",
            "Epoch 131/150\n",
            "4/4 - 0s - loss: 0.3912 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 132/150\n",
            "4/4 - 0s - loss: 0.3901 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 133/150\n",
            "4/4 - 0s - loss: 0.3884 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 134/150\n",
            "4/4 - 0s - loss: 0.3876 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n",
            "Epoch 135/150\n",
            "4/4 - 0s - loss: 0.3854 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 136/150\n",
            "4/4 - 0s - loss: 0.3858 - accuracy: 0.9500 - 22ms/epoch - 6ms/step\n",
            "Epoch 137/150\n",
            "4/4 - 0s - loss: 0.3843 - accuracy: 0.9500 - 24ms/epoch - 6ms/step\n",
            "Epoch 138/150\n",
            "4/4 - 0s - loss: 0.3820 - accuracy: 0.9500 - 15ms/epoch - 4ms/step\n",
            "Epoch 139/150\n",
            "4/4 - 0s - loss: 0.3811 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n",
            "Epoch 140/150\n",
            "4/4 - 0s - loss: 0.3806 - accuracy: 0.9500 - 22ms/epoch - 5ms/step\n",
            "Epoch 141/150\n",
            "4/4 - 0s - loss: 0.3807 - accuracy: 0.9400 - 20ms/epoch - 5ms/step\n",
            "Epoch 142/150\n",
            "4/4 - 0s - loss: 0.3811 - accuracy: 0.9400 - 22ms/epoch - 5ms/step\n",
            "Epoch 143/150\n",
            "4/4 - 0s - loss: 0.3787 - accuracy: 0.9400 - 20ms/epoch - 5ms/step\n",
            "Epoch 144/150\n",
            "4/4 - 0s - loss: 0.3750 - accuracy: 0.9500 - 20ms/epoch - 5ms/step\n",
            "Epoch 145/150\n",
            "4/4 - 0s - loss: 0.3726 - accuracy: 0.9500 - 16ms/epoch - 4ms/step\n",
            "Epoch 146/150\n",
            "4/4 - 0s - loss: 0.3740 - accuracy: 0.9400 - 21ms/epoch - 5ms/step\n",
            "Epoch 147/150\n",
            "4/4 - 0s - loss: 0.3729 - accuracy: 0.9500 - 27ms/epoch - 7ms/step\n",
            "Epoch 148/150\n",
            "4/4 - 0s - loss: 0.3707 - accuracy: 0.9400 - 20ms/epoch - 5ms/step\n",
            "Epoch 149/150\n",
            "4/4 - 0s - loss: 0.3689 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n",
            "Epoch 150/150\n",
            "4/4 - 0s - loss: 0.3673 - accuracy: 0.9500 - 25ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4eb46e1ae0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}